---
layout: post
title: "Rethinking Normalization and Elimination Singularity in Neural Networks"
tags: ["arxiv","network design"]
date: 2019-11-29 01:06:04 +0900
---

ニューロンが発火しなくなるelimination sigularityと各種正規化層の関係を調べ，バッチ正規化にはESの問題を回避する能力があるが，チャンネルベースのlayer normalizationやgroup normalizationにはそのような性質が無いことを明らかにした．このことを踏まえ，ESを回避できるチャンネルベース正規化層としてbatch channel normalizationを提案．

## 基本情報
### 会議・論文誌

### 論文リンク
https://arxiv.org/abs/1911.09738

### 著者・所属
Siyuan Qiao, Huiyu Wang, Chenxi Liu, Wei Shen, Alan Yuille

### 投稿日

## 新規性

## 手法

## 結果

## 議論・コメント

## 関連文献


## Original issue and comments

https://github.com/yoshum/daily-research-news/issues/127
