---
layout: post
title: "Landscape Connectivity and Dropout Stability of SGD Solutions for Over-parameterized Neural Networks"
tags: ["DL theory","loss landscape"]
date: 2019-12-24 13:49:33 +0900
---

深層学習のロス関数は非凸で多数の局所最適が存在し，それらは互いに孤立している．しかし，パラメータの多いモデルではSGD解の間にロスがほぼ一定値を取る経路が存在し，over-parametrizedになるにしたがって，その経路上でのロスが局所解での値に近づく（経路が平坦になる）ことを証明した．

## 基本情報
### 会議・論文誌

### 論文リンク
https://arxiv.org/abs/1912.10095

### 著者・所属
Alexander Shevchenko, Marco Mondelli

## 新規性

## 手法

## 結果

## 議論・コメント

## 関連文献


## Original issue and comments

https://github.com/yoshum/daily-research-news/issues/157
